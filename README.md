# Token Labs ğŸš€

[![Deploy and Benchmark](https://github.com/elizabetht/token-labs/actions/workflows/deploy-and-benchmark.yml/badge.svg)](https://github.com/elizabetht/token-labs/actions/workflows/deploy-and-benchmark.yml)
[![Build vLLM](https://github.com/elizabetht/token-labs/actions/workflows/build-and-push.yml/badge.svg?event=push)](https://github.com/elizabetht/token-labs/actions/workflows/build-and-push.yml)
[![Latest Release](https://img.shields.io/github/v/tag/elizabetht/token-labs?label=Latest%20Release)](https://github.com/elizabetht/token-labs/releases)

Self-hosted LLM inference on NVIDIA DGX Spark with automated benchmarking and cost analysis.

## ğŸ“Š Latest Benchmark Results

| Metric | Prefill (Input) | Decode (Output) |
|--------|-----------------|-----------------|
| Throughput | 3,203 tok/s | 520 tok/s |
| Cost/1M tokens | $0.006 | $0.037 |

ğŸ‘‰ **[View Full Benchmark Results](https://elizabetht.github.io/token-labs/benchmark-results.html)**

ğŸ‘‰ **[Raw JSON Data](https://elizabetht.github.io/token-labs/benchmark-results.json)**

## ğŸ—ï¸ Architecture

- **Hardware**: NVIDIA DGX Spark (Grace Hopper, ARM64)
- **Inference Engine**: [vLLM](https://github.com/vllm-project/vllm)
- **Model**: Meta Llama 3.1 8B Instruct
- **CI/CD**: GitHub Actions with self-hosted runner

## ğŸ’° Cost Economics

DGX Spark running costs:
- Hardware amortization: ~$0.05/hr ($4000 over 3 years @ 30% utilization)
- Electricity: ~$0.02/hr
- **Total: ~$0.07/hour**

## ğŸ”— Links

- [Live Demo](https://elizabetht.github.io/token-labs/)
- [Benchmark Results](https://elizabetht.github.io/token-labs/benchmark-results.html)
- [GitHub Actions](https://github.com/elizabetht/token-labs/actions)

## ğŸ¯ Accuracy Testing

Token Labs includes automated accuracy testing using the [IFEval benchmark](https://github.com/oKatanaaa/ifeval) to ensure model quality is maintained across different configurations and quantizations.

### Baseline Comparison

The workflow automatically compares model accuracy against established baselines:

**Baseline Model**: `meta-llama/Llama-3.1-8B-Instruct` (unquantized)
- Establishes reference accuracy for instruction-following capability
- Baseline values are auto-updated when running the baseline model
- See [`baselines/`](baselines/) for baseline configurations

**Quantized Models**:
- `tokenlabsdotrun/Llama-3.1-8B-ModelOpt-NVFP4` - FP4 quantized variant
- `tokenlabsdotrun/Llama-3.1-8B-ModelOpt-FP8` - FP8 quantized variant

### Running Comparisons

1. **Establish Baseline** (first time or to update):
   ```bash
   # Via GitHub Actions UI
   # Select model: meta-llama/Llama-3.1-8B-Instruct
   # This will update the baseline values
   ```

2. **Compare Quantized Model**:
   ```bash
   # Via GitHub Actions UI
   # Select model: tokenlabsdotrun/Llama-3.1-8B-ModelOpt-NVFP4
   # Workflow will automatically compare against baseline
   ```

### Comparison Thresholds

Models are compared using Â±5% accuracy threshold on IFEval metrics:
- âœ… **PASS**: Accuracy within 5% of baseline
- âŒ **FAIL**: Accuracy degraded >5% from baseline
- ğŸ‰ **IMPROVED**: Accuracy improved beyond baseline

See [`baselines/README.md`](baselines/README.md) for detailed documentation.

## ğŸ“ Repository Structure

```
â”œâ”€â”€ Dockerfile              # vLLM build for ARM64/CUDA 13.0
â”œâ”€â”€ baselines/              # Baseline accuracy values for comparison
â”‚   â”œâ”€â”€ README.md           # Documentation for baseline testing
â”‚   â””â”€â”€ llama-3.1-8b-instruct.json  # Baseline for Llama 3.1 8B
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ index.html          # Main landing page
â”‚   â”œâ”€â”€ benchmark-results.html  # Detailed benchmark results
â”‚   â””â”€â”€ benchmark-results.json  # Raw JSON data (auto-updated)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ compare_baseline.py # Compare accuracy against baseline
â”‚   â”œâ”€â”€ evaluate_accuracy.py # Run IFEval accuracy evaluation
â”‚   â”œâ”€â”€ generate_results.py # Generate benchmark result files
â”‚   â””â”€â”€ update_pricing.py   # Updates pricing in docs
â””â”€â”€ .github/workflows/
    â”œâ”€â”€ build-and-push.yml      # Build vLLM Docker image
    â””â”€â”€ deploy-and-benchmark.yml # Deploy and run benchmarks
```

## License

MIT
