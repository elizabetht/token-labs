[
  {
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "dgx_cost_per_hour": 0.1112,
    "image_tag": "ghcr.io/elizabetht/token-labs/vllm-serve:v0.1.0",
    "prefill": {
      "tokens_per_second": 710.34,
      "cost_per_million_tokens": 0.0434,
      "latency": {
        "mean_ttft_ms": 168976.11,
        "median_ttft_ms": 221021.67,
        "p99_ttft_ms": 451348.25,
        "mean_tpot_ms": 205.55,
        "median_tpot_ms": 208.21,
        "p99_tpot_ms": 367.87,
        "mean_itl_ms": 205.55,
        "median_itl_ms": 160.75,
        "p99_itl_ms": 905.83
      }
    },
    "cached": {
      "tokens_per_second": 0.0,
      "cost_per_million_tokens": 0.0,
      "latency": {
        "mean_ttft_ms": 0.0,
        "median_ttft_ms": 0.0,
        "p99_ttft_ms": 0.0,
        "mean_tpot_ms": 0.0,
        "median_tpot_ms": 0.0,
        "p99_tpot_ms": 0.0,
        "mean_itl_ms": 0.0,
        "median_itl_ms": 0.0,
        "p99_itl_ms": 0.0
      }
    },
    "decode": {
      "tokens_per_second": 284.44,
      "cost_per_million_tokens": 0.1085,
      "latency": {
        "mean_ttft_ms": 10536.75,
        "median_ttft_ms": 10078.24,
        "p99_ttft_ms": 20176.81,
        "mean_tpot_ms": 238.47,
        "median_tpot_ms": 247.4,
        "p99_tpot_ms": 339.66,
        "mean_itl_ms": 238.47,
        "median_itl_ms": 162.94,
        "p99_itl_ms": 823.13
      }
    },
    "timestamp": "2025-12-15T06:37:15.778238Z",
    "vllm_server_args": {
      "gpu_memory_utilization": 0.6,
      "max_model_len": 131072,
      "kv_transfer_config": null,
      "prefix_caching": false,
      "speculative_decoding": false
    },
    "lmcache_config": {
      "enabled": false,
      "chunk_size": null,
      "local_cpu": null,
      "max_local_cpu_size": null
    },
    "benchmark_args": {
      "prefill_test": {
        "num_prompts": 100,
        "request_rate": 10,
        "input_len": 3072,
        "output_len": 1024,
        "ratio": "3072:1024 input:output",
        "total_tokens": 4096
      },
      "decode_test": {
        "num_prompts": 100,
        "request_rate": 10,
        "input_len": 1024,
        "output_len": 3072,
        "ratio": "1024:3072 input:output",
        "total_tokens": 4096
      },
      "cache_test": {
        "dataset": "prefix_repetition",
        "num_prompts": 100,
        "prefix_len": 512,
        "suffix_len": 128,
        "num_prefixes": 5,
        "output_len": 128,
        "description": "Tests LMCache with repeated prefixes"
      }
    },
    "hardware": {
      "platform": "NVIDIA DGX Spark",
      "gpu": "Grace Hopper",
      "architecture": "ARM64"
    },
    "version": "0.1.0"
  },
  {
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "dgx_cost_per_hour": 0.1112,
    "image_tag": "ghcr.io/elizabetht/token-labs/vllm-serve:v0.2.0",
    "prefill": {
      "tokens_per_second": 634.92,
      "cost_per_million_tokens": 0.0486,
      "latency": {
        "mean_ttft_ms": 181337.67,
        "median_ttft_ms": 216998.45,
        "p99_ttft_ms": 520223.12,
        "mean_tpot_ms": 233.5,
        "median_tpot_ms": 207.98,
        "p99_tpot_ms": 427.11,
        "mean_itl_ms": 233.5,
        "median_itl_ms": 161.23,
        "p99_itl_ms": 984.48
      }
    },
    "cached": {
      "tokens_per_second": 3491.14,
      "cost_per_million_tokens": 0.0088,
      "latency": {
        "mean_ttft_ms": 4378.23,
        "median_ttft_ms": 4493.25,
        "p99_ttft_ms": 6777.31,
        "mean_tpot_ms": 136.3,
        "median_tpot_ms": 135.67,
        "p99_tpot_ms": 160.27,
        "mean_itl_ms": 136.33,
        "median_itl_ms": 120.81,
        "p99_itl_ms": 813.21
      }
    },
    "decode": {
      "tokens_per_second": 236.01,
      "cost_per_million_tokens": 0.1308,
      "latency": {
        "mean_ttft_ms": 13296.9,
        "median_ttft_ms": 12407.17,
        "p99_ttft_ms": 29175.59,
        "mean_tpot_ms": 312.51,
        "median_tpot_ms": 319.44,
        "p99_tpot_ms": 408.62,
        "mean_itl_ms": 312.51,
        "median_itl_ms": 163.57,
        "p99_itl_ms": 919.65
      }
    },
    "timestamp": "2025-12-15T07:19:29.547715Z",
    "vllm_server_args": {
      "gpu_memory_utilization": 0.6,
      "max_model_len": 131072,
      "kv_transfer_config": null,
      "prefix_caching": false,
      "speculative_decoding": false
    },
    "lmcache_config": {
      "enabled": false,
      "chunk_size": null,
      "local_cpu": null,
      "max_local_cpu_size": null
    },
    "benchmark_args": {
      "prefill_test": {
        "num_prompts": 100,
        "request_rate": 10,
        "input_len": 3072,
        "output_len": 1024,
        "ratio": "3072:1024 input:output",
        "total_tokens": 4096
      },
      "decode_test": {
        "num_prompts": 100,
        "request_rate": 10,
        "input_len": 1024,
        "output_len": 3072,
        "ratio": "1024:3072 input:output",
        "total_tokens": 4096
      },
      "cache_test": {
        "dataset": "prefix_repetition",
        "num_prompts": 100,
        "prefix_len": 512,
        "suffix_len": 128,
        "num_prefixes": 5,
        "output_len": 128,
        "description": "Tests LMCache with repeated prefixes"
      }
    },
    "hardware": {
      "platform": "NVIDIA DGX Spark",
      "gpu": "Grace Hopper",
      "architecture": "ARM64"
    },
    "version": "0.2.0"
  },
  {
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "dgx_cost_per_hour": 0.1112,
    "image_tag": "ghcr.io/elizabetht/token-labs/vllm-serve:v0.3.0",
    "prefill": {
      "tokens_per_second": 492.03,
      "cost_per_million_tokens": 0.0627,
      "latency": {
        "mean_ttft_ms": 0.0,
        "median_ttft_ms": 0.0,
        "p99_ttft_ms": 0.0,
        "mean_tpot_ms": 0.0,
        "median_tpot_ms": 0.0,
        "p99_tpot_ms": 0.0,
        "mean_itl_ms": 0.0,
        "median_itl_ms": 0.0,
        "p99_itl_ms": 0.0
      }
    },
    "cached": {
      "tokens_per_second": 2682.67,
      "cost_per_million_tokens": 0.0115,
      "latency": {
        "mean_ttft_ms": 0.0,
        "median_ttft_ms": 0.0,
        "p99_ttft_ms": 0.0,
        "mean_tpot_ms": 0.0,
        "median_tpot_ms": 0.0,
        "p99_tpot_ms": 0.0,
        "mean_itl_ms": 0.0,
        "median_itl_ms": 0.0,
        "p99_itl_ms": 0.0
      }
    },
    "decode": {
      "tokens_per_second": 205.99,
      "cost_per_million_tokens": 0.1499,
      "latency": {
        "mean_ttft_ms": 0.0,
        "median_ttft_ms": 0.0,
        "p99_ttft_ms": 0.0,
        "mean_tpot_ms": 0.0,
        "median_tpot_ms": 0.0,
        "p99_tpot_ms": 0.0,
        "mean_itl_ms": 0.0,
        "median_itl_ms": 0.0,
        "p99_itl_ms": 0.0
      }
    },
    "timestamp": "2026-01-12T02:00:35.268334Z",
    "vllm_server_args": {
      "gpu_memory_utilization": 0.6,
      "max_model_len": 131072,
      "kv_transfer_config": null,
      "prefix_caching": false,
      "speculative_decoding": false
    },
    "lmcache_config": {
      "enabled": false,
      "chunk_size": null,
      "local_cpu": null,
      "max_local_cpu_size": null
    },
    "benchmark_args": {
      "prefill_test": {
        "num_prompts": 100,
        "request_rate": 10,
        "input_len": 3072,
        "output_len": 1024,
        "ratio": "3072:1024 input:output",
        "total_tokens": 4096
      },
      "decode_test": {
        "num_prompts": 100,
        "request_rate": 10,
        "input_len": 1024,
        "output_len": 3072,
        "ratio": "1024:3072 input:output",
        "total_tokens": 4096
      },
      "cache_test": {
        "dataset": "prefix_repetition",
        "num_prompts": 100,
        "prefix_len": 512,
        "suffix_len": 128,
        "num_prefixes": 5,
        "output_len": 128,
        "description": "Tests LMCache with repeated prefixes"
      }
    },
    "hardware": {
      "platform": "NVIDIA DGX Spark",
      "gpu": "Grace Hopper",
      "architecture": "ARM64"
    },
    "accuracy": {
      "ifeval": {
        "prompt_level_accuracy": 0.0,
        "instruction_level_accuracy": 0.0,
        "num_samples": 50,
        "evaluated": true
      }
    },
    "version": "0.3.0"
  }
]