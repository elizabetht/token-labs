# AIGatewayRoute — AI-aware routing for OpenAI-compatible API traffic
#
# Envoy AI Gateway's AIGatewayRoute replaces the BBR + HTTPRoute combo.
# The AI Gateway ext_proc automatically:
#   1. Extracts the "model" field from the request body
#   2. Sets the x-ai-eg-model header
#   3. Routes to the matching InferencePool backend
#
# No BBR, no ConfigMaps, no EnvoyExtensionPolicy needed.
---
apiVersion: aigateway.envoyproxy.io/v1alpha1
kind: AIGatewayRoute
metadata:
  name: llm-inference
  namespace: token-labs
spec:
  parentRefs:
  - name: token-labs-gateway
    kind: Gateway
    group: gateway.networking.k8s.io
  rules:
  # Llama 3.1 8B — routed to token-labs-pool (spark-01)
  - matches:
    - headers:
      - type: Exact
        name: x-ai-eg-model
        value: meta-llama/Llama-3.1-8B-Instruct
    backendRefs:
    - group: inference.networking.k8s.io
      kind: InferencePool
      name: token-labs-pool
  # Nemotron VL 12B FP8 — routed to nemotron-vl-pool (spark-02)
  - matches:
    - headers:
      - type: Exact
        name: x-ai-eg-model
        value: nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-FP8
    backendRefs:
    - group: inference.networking.k8s.io
      kind: InferencePool
      name: nemotron-vl-pool
  # Token cost tracking — AI Gateway extracts token usage from responses
  # and exposes it as metadata for rate limiting and observability.
  llmRequestCosts:
  - metadataKey: llm_input_token
    type: InputToken
  - metadataKey: llm_output_token
    type: OutputToken
  - metadataKey: llm_total_token
    type: TotalToken
